<!doctype html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-alpha.69">
<title data-react-helmet="true">Methods | Personalization of Generalized Activity Recognition Models</title><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"><meta data-react-helmet="true" name="docusaurus_language" content="en"><meta data-react-helmet="true" name="docusaurus_version" content="current"><meta data-react-helmet="true" name="docusaurus_tag" content="docs-default-current"><meta data-react-helmet="true" property="og:title" content="Methods | Personalization of Generalized Activity Recognition Models"><meta data-react-helmet="true" name="description" content="As we know, the pipeline for activity recognition is as shown below, and we have discussed the dataset collection in the previous section."><meta data-react-helmet="true" property="og:description" content="As we know, the pipeline for activity recognition is as shown below, and we have discussed the dataset collection in the previous section."><meta data-react-helmet="true" property="og:url" content="https://ub31.github.io/ASR/docs/doc7"><link data-react-helmet="true" rel="shortcut icon" href="/ASR/img/logohead.png"><link data-react-helmet="true" rel="canonical" href="https://ub31.github.io/ASR/docs/doc7"><link rel="stylesheet" href="/ASR/styles.edc99cb9.css">
<link rel="preload" href="/ASR/styles.71d10a56.js" as="script">
<link rel="preload" href="/ASR/runtime~main.366c8f14.js" as="script">
<link rel="preload" href="/ASR/main.6fc68446.js" as="script">
<link rel="preload" href="/ASR/1.8f67cab4.js" as="script">
<link rel="preload" href="/ASR/35.da5c47bd.js" as="script">
<link rel="preload" href="/ASR/36.a067ae9c.js" as="script">
<link rel="preload" href="/ASR/f976f453.247ede68.js" as="script">
<link rel="preload" href="/ASR/34.1489086d.js" as="script">
<link rel="preload" href="/ASR/2eff71e3.1b18dba2.js" as="script">
</head>
<body>
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<nav aria-label="Skip navigation links"><button type="button" tabindex="0" class="skipToContent_2AhQ">Skip to main content</button></nav><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><div aria-label="Navigation bar toggle" class="navbar__toggle" role="button" tabindex="0"><svg xmlns="http://www.w3.org/2000/svg" width="30" height="30" viewBox="0 0 30 30" role="img" focusable="false"><title>Menu</title><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></div><a class="navbar__brand" href="/ASR/"><img src="/ASR/img/logo.jpeg" alt="My Site Logo" class="themedImage_2E_h themedImage--light_AouX navbar__logo"><img src="/ASR/img/logo.jpeg" alt="My Site Logo" class="themedImage_2E_h themedImage--dark_1YPN navbar__logo"><strong class="navbar__title">Home</strong></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/ASR/docs/">Description</a></div><div class="navbar__items navbar__items--right"><div class="react-toggle react-toggle--disabled displayOnlyInLargeViewport_2aTZ"><div class="react-toggle-track"><div class="react-toggle-track-check"><span class="toggle_BsTx">ðŸŒœ</span></div><div class="react-toggle-track-x"><span class="toggle_BsTx">ðŸŒž</span></div></div><div class="react-toggle-thumb"></div><input type="checkbox" disabled="" aria-label="Dark mode toggle" class="react-toggle-screenreader-only"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div><div class="navbar-sidebar"><div class="navbar-sidebar__brand"><a class="navbar__brand" href="/ASR/"><img src="/ASR/img/logo.jpeg" alt="My Site Logo" class="themedImage_2E_h themedImage--light_AouX navbar__logo"><img src="/ASR/img/logo.jpeg" alt="My Site Logo" class="themedImage_2E_h themedImage--dark_1YPN navbar__logo"><strong class="navbar__title">Home</strong></a></div><div class="navbar-sidebar__items"><div class="menu"><ul class="menu__list"><li class="menu__list-item"><a aria-current="page" class="menu__link navbar__link--active" href="/ASR/docs/">Description</a></li></ul></div></div></div></nav><div class="main-wrapper"><div class="docPage_2gpo"><div class="docSidebarContainer_3_JD" role="complementary"><div class="sidebar_2urC"><div class="menu menu--responsive thin-scrollbar menu_5FrY"><button aria-label="Open Menu" aria-haspopup="true" class="button button--secondary button--sm menu__button" type="button"><svg aria-label="Menu" class="sidebarMenuIcon_Dm3K" xmlns="http://www.w3.org/2000/svg" height="24" width="24" viewBox="0 0 32 32" role="img" focusable="false"><title>Menu</title><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><ul class="menu__list"><li class="menu__list-item"><a class="menu__link menu__link--sublist menu__link--active" href="#!">Project Description</a><ul class="menu__list"><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/ASR/docs/">Introduction</a></li><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/ASR/docs/doc3">Related Work &amp; Goals</a></li><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/ASR/docs/doc5">Dataset</a></li><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/ASR/docs/doc6">Exploratory analysis</a></li><li class="menu__list-item"><a aria-current="page" class="menu__link menu__link--active active" tabindex="0" href="/ASR/docs/doc7">Methods</a></li><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/ASR/docs/doc8">Experimental Result &amp; Analysis</a></li><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/ASR/docs/doc9">Conclusion</a></li><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/ASR/docs/doc10">Future Work</a></li><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/ASR/docs/doc11">Appendix</a></li></ul></li></ul></div></div></div><main class="docMainContainer_3EyW"><div class="container padding-vert--lg docItemWrapper_39qw"><div class="row"><div class="col docItemCol_2ASc"><div class="docItemContainer_3QWW"><article><header><h1 class="docTitle_1Lrw">Methods</h1></header><div class="markdown"><p>As we know, the pipeline for activity recognition is as shown below, and we have discussed the dataset collection in the previous section.</p><p><img alt="img" src="/ASR/assets/images/71-c034c688c5e7c7913aedb1667a1f06a7.png"></p><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="feature-extraction"></a>Feature Extraction<a class="hash-link" href="#feature-extraction" title="Direct link to heading">#</a></h3><p>We move on to the next step which is <strong>frame</strong> and <strong>feature extraction</strong>.  We perform basic preprocessing to drop samples in the start and end of the data for each activity for all subjects. The frames are extracted for a window of <strong>100ms</strong> with <strong>50ms overlapping</strong> frames. Since our goal is to study personalization, we did not experiment on different frame sizes. The data is recorded at <strong>100Hz</strong> hence we selected 100ms frames with 50% overlap. We have used time-domain features that have worked well in previous work designed for accelerometer data. We believe that since the accelerometer signals are captured in time domain, these features are sufficient to model the activities. </p><p>We extracted the following features for each <code>frame, mean, variance, standard deviation, median, third and fourth moment, 25,50 and 75 percentile, skewness, kurtosis and rms of signal</code>. We obtain the above features for the raw accelerometer signals along X,Y and Z axis as well as the magnitude signal. In total we get 48 features. The choice of these features are based upon previous works as well as assignments in class. </p><table><thead><tr><th>Features Extracted</th><th align="center">Number of Features</th></tr></thead><tbody><tr><td>Mean</td><td align="center">4 (AccX,AccY,AccZ,MagAcc)</td></tr><tr><td>Median</td><td align="center">4</td></tr><tr><td>Variance</td><td align="center">4</td></tr><tr><td>Standard Deviation</td><td align="center">4</td></tr><tr><td>Third Moment</td><td align="center">4</td></tr><tr><td>Fourth Moment</td><td align="center">4</td></tr><tr><td>25th Percentile</td><td align="center">4</td></tr><tr><td>50th Percentile</td><td align="center">4</td></tr><tr><td>75th Percentile</td><td align="center">4</td></tr><tr><td>Skewness</td><td align="center">4</td></tr><tr><td>Kurtosis</td><td align="center">4</td></tr><tr><td>RMS</td><td align="center">4</td></tr><tr><td><strong>Total</strong></td><td align="center">48</td></tr></tbody></table><p>Once we obtain the features, we train our baseline models, this is discussed in detail in the next section. We use a <strong>RandomForestClassifier</strong> as the machine learning model. The choice of RandomForestClassifier is from prior literature review as well as widespread use of ensembling methods. Ensemble methods help to achieve the <code>bias-variance tradeoff</code>. When the <strong>number of estimators</strong> <em>increases</em> the <strong>variance</strong> can be reduced, by averaging out across the different base learners(decision tree). In addition to this random forest identifies <strong>different subsets of features</strong> to train the different base learners thereby <strong>preventing overfitting</strong>.</p><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="active-learning"></a>Active learning<a class="hash-link" href="#active-learning" title="Direct link to heading">#</a></h2><p>We identify the most informative samples or the samples where the model is uncertain about itâ€™s prediction and use a pool-based strategy to query for these samples. The setup for this is, there is a set of labeled instances, a set of unlabeled instances, and a golden oracle which provides the label for an unlabeled instance when queried. During each iteration we find the instance which we want the oracle to label using different query strategies and then add them to the labeled pool to retrain the model and evaluate them. In this way the model starts to gradually learn from the additional samples provided.</p><p><img alt="img" src="/ASR/assets/images/AL-559ffa17fd9aae2de5175750035996a2.png"></p><p>The main query strategies which we analyzed are based on Uncertainty sampling. The usefulness of a instance is calculated based on different measures like classification uncertainty, classification margin and classification entropy. We briefly explain the measures below, </p><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="ensembling-with-entropy"></a>Ensembling with entropy<a class="hash-link" href="#ensembling-with-entropy" title="Direct link to heading">#</a></h3><p>In this method, we use two models (RandomForest and MLPClassifier) to train a classifier and then evaluate the predictions of both the classifiers on the unlabeled instance.  Then we measure the <strong>entropy in the probability distribution of the predictions</strong> from the two models. This shows if the unlabeled instance has a different probability distribution from one model to another which indicates uncertainty.</p><p><img alt="img" src="/ASR/assets/images/algo2-e37329f74c6d7fe928a8d3a71da79f05.png"></p><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="least-confidence"></a>Least confidence<a class="hash-link" href="#least-confidence" title="Direct link to heading">#</a></h3><p>This is one of the simplest methods to measure the uncertainty. We do this by measuring the prediction probability from the model, and select the samples whose <strong>confident predictions are less than 0.5</strong> as uncertain. This implies that the model is able to predict the class only with 0.5 probability making it uncertain.</p><p><img alt="img" src="/ASR/assets/images/algo1-54de6a09386250056c225ebc002bfeac.png"></p><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="minimum-margin"></a>Minimum margin<a class="hash-link" href="#minimum-margin" title="Direct link to heading">#</a></h3><p>The most intuitive form of uncertainty sampling is the difference between the two most confident predictions. We measure this by identifying for the label that the model predicted, how confident is this prediction than the next most confident label prediction by the model. In other words it measures the <strong>difference in confidence between the first and second most likely predictions</strong>. </p><p><img alt="img" src="/ASR/assets/images/algo3-47258f05cad10af31e047439de7c19f1.png"></p><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="random-sampling"></a>Random sampling<a class="hash-link" href="#random-sampling" title="Direct link to heading">#</a></h3><p>For random sampling, we add <strong>randomly selected samples</strong> from the unlabeled pool without any criterion and to the labeled set.</p><p><img alt="img" src="/ASR/assets/images/algo4-525ece7441ef4e4c579c33800eec694c.png"></p><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="semi-supervised-learning"></a>Semi-supervised learning<a class="hash-link" href="#semi-supervised-learning" title="Direct link to heading">#</a></h2><p>The major difference between active learning and semi-supervised learning is that the latter uses the unlabeled examples for improving the accuracy whereas active learning approaches query an oracle to label the data.</p><p>The goal of the semi-supervised approach is to understand whether we can label the unlabeled samples from the model and use it to retrain the model. For this method, we have a set of labeled instances, a set of unlabeled instances, and a test set.</p><p>We implement self-training which makes use of a modelâ€™s own prediction on unlabeled data in order to obtain additional information that can be used during training. The basic idea is to build a model on the labeled data and then use this model to estimate the labels for the unlabeled pool. The most confident label values are taken and the newly labeled data are then used along with the originally labeled instances to retrain the model. This procedure is repeated until all samples are labeled.</p><p><img alt="img" src="/ASR/assets/images/semi-supervised-9e9b79fb1cda14493489f196fe397984.png"></p><p>However, semi-supervised learning is not able to obtain enough new samples to retrain the model if we select only the samples with high confidence. We implement a mixed strategy consisting of active and semi- supervised, where at each iteration we sample uncertain samples and query the oracle for the labels to add to the training data and then use another set of instances, identify their predictions in a self-training manner and then add the most confident predictions to the training dataset with the predicted labels as the actual labels.</p></div></article><div class="margin-vert--lg"><nav class="pagination-nav" aria-label="Blog list page navigation"><div class="pagination-nav__item"><a class="pagination-nav__link" href="/ASR/docs/doc6"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Â« Activity Exploration</div></a></div><div class="pagination-nav__item pagination-nav__item--next"><a class="pagination-nav__link" href="/ASR/docs/doc8"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Experimental Result &amp; Analysis Â»</div></a></div></nav></div></div></div><div class="col col--3"><div class="tableOfContents_3SO_ thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#feature-extraction" class="table-of-contents__link">Feature Extraction</a></li><li><a href="#active-learning" class="table-of-contents__link">Active learning</a><ul><li><a href="#ensembling-with-entropy" class="table-of-contents__link">Ensembling with entropy</a></li><li><a href="#least-confidence" class="table-of-contents__link">Least confidence</a></li><li><a href="#minimum-margin" class="table-of-contents__link">Minimum margin</a></li><li><a href="#random-sampling" class="table-of-contents__link">Random sampling</a></li></ul></li><li><a href="#semi-supervised-learning" class="table-of-contents__link">Semi-supervised learning</a></li></ul></div></div></div></div></main></div></div></div>
<script src="/ASR/styles.71d10a56.js"></script>
<script src="/ASR/runtime~main.366c8f14.js"></script>
<script src="/ASR/main.6fc68446.js"></script>
<script src="/ASR/1.8f67cab4.js"></script>
<script src="/ASR/35.da5c47bd.js"></script>
<script src="/ASR/36.a067ae9c.js"></script>
<script src="/ASR/f976f453.247ede68.js"></script>
<script src="/ASR/34.1489086d.js"></script>
<script src="/ASR/2eff71e3.1b18dba2.js"></script>
</body>
</html>